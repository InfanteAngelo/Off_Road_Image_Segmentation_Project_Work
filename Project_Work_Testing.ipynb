{"cells":[{"cell_type":"markdown","id":"98be07a8","metadata":{"id":"98be07a8"},"source":["## Colab Setup"]},{"cell_type":"code","execution_count":null,"id":"59c53af9","metadata":{"vscode":{"languageId":"plaintext"},"id":"59c53af9"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir(\"/content/drive/My Drive/Didattica/ML/exam_2024-2025/project_work_segmentazione_off-road/\")"]},{"cell_type":"markdown","id":"25f9664a","metadata":{"id":"25f9664a"},"source":["## General Setup"]},{"cell_type":"code","execution_count":null,"id":"b683f294","metadata":{"vscode":{"languageId":"plaintext"},"id":"b683f294"},"outputs":[],"source":["\n","from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, DeepLabV3_MobileNet_V3_Large_Weights\n","from torch import nn\n","import os\n","import torch\n","import albumentations as A\n","\n","# Class Mapper\n","COLOR_TO_ID = {\n","    (255, 255, 255): 0,   # Background\n","    (178, 176, 153): 1,   # Smooth Trail\n","    (128, 255, 0):   2,   # Traversable grass\n","    (156, 76, 30):   3,   # Rough Trail\n","    (255, 0, 128):   4,   # Puddle\n","    (255, 0, 0):     5,   # Obstacle\n","    (0, 160, 0):     6,   # Non Traversable Low Vegetation\n","    (40, 80, 0):     7,   # High Vegetation\n","    (1, 88, 255):    8    # Sky\n","}\n","\n","IMG_HEIGHT = 512\n","IMG_WIDTH = 512\n","TEST_DIR = './resources/test'       # Change to the correct directory\n","MODEL_SAVE_PATH = 'best_segmentation_model.pth'"]},{"metadata":{"id":"ae70d3ea41042f8f"},"cell_type":"markdown","source":["## Model Architecture"],"id":"ae70d3ea41042f8f"},{"metadata":{"id":"93b6529ac66fa7d1"},"cell_type":"code","outputs":[],"execution_count":null,"source":["\n","class SegmentationModel(nn.Module):\n","    def __init__(self, num_classes=9):\n","        super(SegmentationModel, self).__init__()\n","\n","        self.model = deeplabv3_mobilenet_v3_large(weights=DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1)\n","\n","        self.model.classifier[-1] = nn.Conv2d(256, num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.model(x)['out']\n","\n","model_summary = SegmentationModel()\n","print(model_summary)"],"id":"93b6529ac66fa7d1"},{"cell_type":"markdown","id":"f2d7dde5","metadata":{"id":"f2d7dde5"},"source":["## Function to plot correctly"]},{"cell_type":"code","execution_count":null,"id":"37b1087f","metadata":{"vscode":{"languageId":"plaintext"},"id":"37b1087f"},"outputs":[],"source":["ID_TO_COLOR = {v: k for k, v in COLOR_TO_ID.items()}\n","\n","# This feature can be used to display images correctly by mapping the various pixels.\n","def id_to_rgb_mask(id_mask_np, id_to_color_map):\n","    h, w = id_mask_np.shape\n","    rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n","    for class_id, color_rgb in id_to_color_map.items():\n","        rgb_mask[id_mask_np == class_id] = color_rgb\n","    return rgb_mask"]},{"cell_type":"markdown","id":"d02005ab","metadata":{"id":"d02005ab"},"source":["## Function to load the model"]},{"cell_type":"code","execution_count":null,"id":"1be8b31b","metadata":{"vscode":{"languageId":"plaintext"},"id":"1be8b31b"},"outputs":[],"source":["\n","def load_model(path, device='cuda'):\n","    model = SegmentationModel().to(device)\n","    model.load_state_dict(torch.load(path, weights_only=True))\n","    return model"]},{"cell_type":"markdown","id":"d1ebc4a0","metadata":{"id":"d1ebc4a0"},"source":["## Function to predict on a single image"]},{"cell_type":"code","execution_count":null,"id":"9d0b4485","metadata":{"vscode":{"languageId":"plaintext"},"id":"9d0b4485"},"outputs":[],"source":["img_transform = A.Compose([\n","    A.Resize(height=IMG_HEIGHT, width=IMG_WIDTH),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    A.ToTensorV2()\n","])\n","\n","def pil_to_tensor(img):\n","    img = np.array(img)\n","    img = img_transform(image=img)['image']\n","    return img\n","\n","def predict(model, image, target_shape, device='cuda'):\n","    model.eval()\n","    with torch.no_grad():\n","        image = Image.fromarray(image)\n","        image_tensor = pil_to_tensor(image).unsqueeze(0).to(device)\n","        output = model(image_tensor)\n","        predictions = torch.nn.functional.softmax(output, dim=1)\n","        pred_labels = torch.argmax(predictions, dim=1)\n","        pred_labels = pred_labels.squeeze(0).cpu().numpy().astype(np.uint8)\n","        if target_shape is not None and pred_labels.shape != target_shape:\n","            pred_labels = np.array(Image.fromarray(pred_labels).resize((target_shape[1], target_shape[0]), resample=Image.NEAREST))\n","    return pred_labels"]},{"cell_type":"markdown","id":"051bb5ba","metadata":{"id":"051bb5ba"},"source":["## Code to test the model"]},{"cell_type":"code","execution_count":null,"id":"78a43afb","metadata":{"vscode":{"languageId":"plaintext"},"id":"78a43afb"},"outputs":[],"source":["import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Metrics\n","def compute_iou(mask1, mask2, label):\n","  intersection = np.sum((mask1 == label) & (mask2 == label))\n","  union = np.sum((mask1 == label) | (mask2 == label))\n","  if union == 0:\n","    return np.nan\n","  return intersection / union\n","def compute_all_iou(mask1, mask2, num_labels=8):\n","  iou_scores = np.zeros((num_labels))\n","  for label in range(num_labels):\n","    iou = compute_iou(mask1, mask2, label+1) # we skip the background label\n","    iou_scores[label] = iou\n","  return iou_scores\n","\n","\n","# Run YOUR LOAD_MODEL FUNCTION\n","model = load_model(path=MODEL_SAVE_PATH)\n","\n","# Main loop\n","test_dir = TEST_DIR  # we will change this path with that of the private test set directory\n","samples = os.listdir(test_dir)\n","IOUs = np.zeros((len(samples), 8))\n","verbose = True\n","\n","for i, subdir in tqdm(enumerate(samples), desc=\"Processing samples\"):\n","    subdir_path = os.path.join(test_dir, subdir)\n","\n","    if os.path.isdir(subdir_path):\n","        # Get the data paths\n","        rgb_path = os.path.join(subdir_path, 'rgb.jpg')\n","        labels_path = os.path.join(subdir_path, 'labels.png')\n","\n","        if os.path.exists(rgb_path) and os.path.exists(labels_path):\n","            if verbose:\n","                print(f\"Processing subdirectory: {subdir}\")\n","\n","            try:  # ATTENTION: any error occurring in this try-catch means that the corresponding IOUs are evaluated as ZERO\n","\n","                # Open images\n","                rgb_image = Image.open(rgb_path)\n","                rgb_array = np.asarray(rgb_image).copy()\n","                labels_image = Image.open(labels_path).copy()\n","                labels_array = np.asarray(labels_image)\n","                if verbose:\n","                    print(f\"  Loaded {rgb_path} and {labels_path}\")\n","\n","                # Run YOUR PREDICT FUNCTION\n","                predicted_labels_array = predict(model=model, image=rgb_array, target_shape=labels_array.shape)\n","\n","                # Evaluate the IOU metric\n","                IOUs[i,:] = compute_all_iou(labels_array, predicted_labels_array)\n","\n","                if verbose:\n","                    labels_vals = np.unique(np.asarray(labels_image))\n","                    print(f\"  Unique labels values: {labels_vals}\")\n","                    predicted_labels_vals = np.unique(np.asarray(predicted_labels_array))\n","                    print(f\"  Unique predicted labels values: {predicted_labels_vals}\")\n","\n","                    plt.subplot(1, 3, 1)\n","                    plt.imshow(rgb_image)\n","                    plt.subplot(1, 3, 2)\n","                    plt.imshow(labels_image)\n","                    plt.subplot(1, 3, 3)\n","                    plt.imshow(predicted_labels_array)\n","                    #plt.imshow(id_to_rgb_mask(predicted_labels_array, ID_TO_COLOR))\n","                    plt.show()\n","\n","                rgb_image.close()\n","                labels_image.close()\n","\n","            except FileNotFoundError:\n","                print(f\"  Error: Could not find image files in {subdir_path}\")\n","            except Exception as e:\n","                print(f\"  Error processing images in {subdir_path}: {e}\")\n","        else:\n","            print(f\"  Skipping subdirectory {subdir}: rgb.jpg or labels.png not found.\")\n","\n","score = np.nanmean(IOUs)\n","print(f\"\\nFinal competition score: {score}\")"]},{"cell_type":"markdown","source":["## More information useful for your analysis"],"metadata":{"id":"shD8Y8v2MiBA"},"id":"shD8Y8v2MiBA"},{"cell_type":"code","source":["import numpy as np\n","np.set_printoptions(precision=3, suppress=True)\n","print(f\"All IOUs:\\n{IOUs}\")\n","print(\"Average IOUs for each:\")\n","print(f\"- class: {np.nanmean(IOUs, 0)}\")\n","print(f\"- image: {np.nanmean(IOUs, 1)}\")"],"metadata":{"id":"SuHkaDqsMo3G"},"id":"SuHkaDqsMo3G","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}